from Parser import Parser
# from ar_corrector.corrector import Corrector
from tashaphyne.stemming import ArabicLightStemmer
# corr = Corrector()

 source_sentence="Ù†ÙØ­Ù’Ù†Ù Ø£ÙÙƒÙÙ„Ù’Ù†ÙØ§ Ø£Ø³Ø¯"
# #source_sentence="Ù†ÙØ­Ù’Ù†Ù "
parser = Parser(model_path=r"C:\Users\tony_\Downloads\stanford-corenlp-4.2.0-models-arabic\edu\stanford\nlp\models\lexparser\arabicFactored.ser.gz",
                path_to_jar=r"C:\Users\tony_\Downloads\stanford-parser-4.2.0\stanford-parser-full-2020-11-17\stanford-parser.jar",
                path_to_models_jar=r"C:\Users\tony_\Downloads\stanford-parser-4.2.0\stanford-parser-full-2020-11-17\stanford-parser-4.2.0-models.jar")

# #parser mac
# # parser = Parser(model_path=r"/Users/TonyDfouny/Downloads/corenlp/edu/stanford/nlp/models/lexparser/arabicFactored.ser.gz",
# #                 path_to_jar=r"/Users/TonyDfouny/Downloads/stanford-parser-full-2020-11-17/stanford-parser.jar",
# #                 path_to_models_jar=r"/Users/TonyDfouny/Downloads/stanford-parser-full-2020-11-17/stanford-parser-4.2.0-models.jar")
#

def ArabicParser(arabicsentence):
    parsedsentence=parser.custom_parse(arabicsentence)
    return parsedsentence

parsedsentence=ArabicParser(source_sentence)
#parsedsentence=['PRP Ù†Ø­Ù†', 'VBD Ø§ÙƒÙ„Ù†Ø§', 'NNP Ø§Ø³Ø¯','VBG Ø§ÙƒÙ„Ù†Ø§']
print (parsedsentence)

def TranslateVerb(verb):
    return None

def TranslateSentence(sourcesentence):
    parsedsentence=ArabicParser(sourcesentence)

    for word in parsedsentence:
        if word[0]!='V':
            word.split()[1]



def verbgrammar(parsedsentence):
    parsedverb = []
    for verb in parsedsentence:
        if 'V' in verb[0]:
            parsedverb.append(verb)

    print(parsedverb)
    ArListem = ArabicLightStemmer()
    presentdict={



    }
    pastdict={

    }
    # stemming word
    for verb in parsedverb:
        stem = ArListem.light_stem(verb)
        # extract stem
        print(ArListem.get_stem())
        # extract root
        print(ArListem.get_prefix())
        print(ArListem.get_suffix())

verbgrammar(parsedverb)


#print(str(parsed[0]))
#parser.custom_print()
# t=parser.custom_print()
# for i in t:
#     print(i)

# Pronouns = [(parent_tag(tag, word)) for parent_tag, word, tag in parsed]
# print('Pronouns = ',Pronouns)


# print(parsedsentence)
# print(parser.custom_parse(source_sentence))

# parser.custom_print()
# parser.tree_draw()

#print(parser.custom_parse(source_sentence))

# def Translator(source_sentence):
#     ####DATABASE####
#     DB = {"Ø£Ù†Ø§": "ğ¤€ğ¤ğ¤Š",
#           "Ù†ÙØ­Ù’Ù†Ù": "ğ¤€ğ¤ğ¤‡ğ¤",
#           "Ø£ÙƒÙ„Øª": "ğ¤€ğ¤Šğ¤‹ğ¤•",
#           "Ø£ÙÙƒÙÙ„Ù’Ù†ÙØ§": "ğ¤€ğ¤Šğ¤‹ğ¤",
#           "Ø£Ø³Ø¯": "ğ¤€ğ¤“ğ¤…"
#           }
#
#     ar_to_phoe_dict = {}
#     for i in source_sentence.split():
#         ar_to_phoe_dict[i] = ''
#
#     for i in ar_to_phoe_dict.keys():
#         if i in DB.keys():
#             ar_to_phoe_dict[i] = DB[i]
#
#     ##Target sentence##
#
#     target_sentence = ""
#     for i in ar_to_phoe_dict.values():
#         target_sentence = target_sentence + " " + i
#
#     print(source_sentence, '\n', target_sentence)
#
#
# Translator(source_sentence)




# result=parser.parse_sentence(u'Ø£Ù†Ø§ Ø£Ù‚ÙˆÙ… Ø¨Ø¨Ù†Ø§Ø¡ Ù…Ù†Ø²Ù„')
# print(result)
# parser.tree_print()
# parser.tree_draw()

###########CORRECTORR##############
#
#
# #####CORRECT WORD SPELLING######
# corr.spell_correct('Ø¨Ø®ØªØ¨') # return 5 corrections with top frequencies
# # [('Ø¨ÙƒØªØ¨', 61), ('Ø¨Ø±ØªØ¨', 22), ('Ø¨Ø®ØªÙ…', 21), ('Ø¨Ø®ØªÙŠ', 9), ('Ø¨Ø®Øª', 7)]
#
# corr.spell_correct('Ø¨Ø®ØªØ¨', 2) # return 2 corrections with top frequencies
# # [('Ø¨ÙƒØªØ¨', 61), ('Ø¨Ø±ØªØ¨', 22),]
#
# corr.spell_correct('Ø¨Ø®ØªØ¨', 1) # return 1 correction with top frequency
# # [('Ø¨ÙƒØªØ¨', 61)]
#
# corr.spell_correct('Ù„ØªÙ…Ø´ØªÙ„Ù…ÙŠØªÙ„ÙƒØ¨', 4) # return the same word
# # Ù„ØªÙ…Ø´ØªÙ„Ù…ÙŠØªÙ„ÙƒØ¨
#
# corr.spell_correct('Ù…Ù†') # return true
# # True
#
#
# #####CONTEXT CORRECTION#####
# sent = 'Ø£ÙƒØ¯Øª Ù‚ÙˆØ§Ø¡Øµ Ø§Ù„ØªÙ…Ø°Ø¯ ÙÙŠ ØªØ´Ø§Ø¯ Ø£Ù†Ù‡Ø§ ØªÙˆØ§Ø¶Ø¶Ù„ Ø·Ø±ÙŠÙ‚Ù‡Ø§ Ù„Ù„Ø¹Ø§Ø­Ù…Ø©'
# print(corr.contextual_correct(sent))
# #Ø£ÙƒØ¯Øª Ù‚ÙˆØ§Øª Ø§Ù„ØªÙ…Ø±Ø¯ ÙÙŠ ØªØ´Ø§Ø¯ Ø£Ù†Ù‡Ø§ ØªÙˆØ§ØµÙ„ Ø·Ø±ÙŠÙ‚Ù‡Ø§ Ù„Ù„Ø¹Ø§ØµÙ…Ø©
#
# sent = 'Ø§ØªØªÙ†ØªÙ‡Ù‰ Ø­Ø¯Ø« Ø¢Ø¨Ù„ Ø§Ù„Ù…Ù†ØªØ¸Ùˆ Ø¨Ø§Ù„Ø¥Ø¹Ù„Ø§Ø® Ø¹Ù† Ù…Ù…ÙˆØ¹Ø© Ù…Ù† Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª'
# print(corr.contextual_correct(sent))
# #Ø§Ù†ØªÙ‡Ù‰ Ø­Ø¯Ø« Ø¢Ø¨Ù„ Ø§Ù„Ù…Ù†ØªØ¸Ø± Ø§Ù„Ø¥Ø¹Ù„Ø§Ù† Ø¹Ù† Ù…Ø¬Ù…ÙˆØ¹Ø© Ù…Ù† Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª